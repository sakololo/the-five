# ğŸ”’ FINAL SANITY CHECK - Critical Review of Round 4 Proposal

**External Auditor: Final Gate**

---

## Proposal Under Review

**Round 4 proposed TWO changes**:
1. Prefix-aware sorting
2. Boundary-safe replacement (regex-based)

---

## ğŸš¨ CRITICAL FLAW #1: Regex Performance & Escaping

### Proposed Code
```typescript
const regex = new RegExp(key.replace(/[.*+?^${}()|[\]\\]/g, '\\$&') + '(?=[\\sã€€]|$)', 'i');
```

### Problems

**A. Regex escaping for Japanese**:
- `key = "ãƒ¯ãƒ³ãƒ”ãƒ¼ã‚¹"` (Japanese Katakana)
- These characters don't need escaping
- BUT the escaping regex `[.*+?^${}()|[\]\\]` only handles ASCII special chars
- What if an alias key contains `(` or `)` or `[`? (e.g., "Re:ã‚¼ãƒ­(1)")
- The escaping WILL work, but it's overly complex for Japanese strings

**B. Performance**:
- Creating a new RegExp on EVERY query is expensive
- This runs for every search
- For a high-traffic app, this could be thousands of regex compilations per second

**C. Case sensitivity**:
- The `'i'` flag makes it case-INsensitive
- But `normalizedChars` is already normalized (Hiraganaâ†’Katakana)
- Why is case-insensitivity needed here?

---

## ğŸš¨ CRITICAL FLAW #2: False Negatives with Boundary Check

### Test Case: Numbers

**Query**: `"ãƒ¯ãƒ³ãƒ”ãƒ¼ã‚¹1"`
**Alias key**: `"ãƒ¯ãƒ³ãƒ”ãƒ¼ã‚¹"`
**Regex**: `/ãƒ¯ãƒ³ãƒ”ãƒ¼ã‚¹(?=[\sã€€]|$)/`

**Does "ãƒ¯ãƒ³ãƒ”ãƒ¼ã‚¹1" match?**
- `"ãƒ¯ãƒ³ãƒ”ãƒ¼ã‚¹1".match(/ãƒ¯ãƒ³ãƒ”ãƒ¼ã‚¹(?=[\sã€€]|$)/)` â†’ **NO MATCH**
- `1` is not a space or end-of-string
- **Result**: No replacement happens
- **Final**: `"ãƒ¯ãƒ³ãƒ”ãƒ¼ã‚¹1"` stays as is

**Is this correct?**
- If user searches "ãƒ¯ãƒ³ãƒ”ãƒ¼ã‚¹1" (ONE PIECE Vol. 1)
- They likely want it normalized to "ONE PIECE 1"
- **Current proposal FAILS this case**

**Fix**: Boundary should include digits and certain punctuation:
```typescript
(?=[\sã€€\d]|$)
```

But then what about:
- `"ãƒ¯ãƒ³ãƒ”ãƒ¼ã‚¹ï¼"` (with exclamation mark)?
- `"ãƒ¯ãƒ³ãƒ”ãƒ¼ã‚¹ãƒ»"` (with middle dot)?

**This is a rabbit hole.**

---

## ğŸš¨ CRITICAL FLAW #3: Prefix Logic Breaks Partial Queries

### Test Case: Hiragana Input

**User types**: `"ã‚ã‚“ã´ãƒ¼ã™"` (Hiragana - mobile keyboard)
**After `normalizeCharacters`**: `"ãƒ¯ãƒ³ãƒ”ãƒ¼ã‚¹"` (converted to Katakana)

**Aliases**:
- `'ãŠã­ã´ãƒ¼ã™': 'ONE PIECE'` (Hiragana in dictionary)
- `'ãƒ¯ãƒ³ãƒ”ãƒ¼ã‚¹': 'ONE PIECE'` (Katakana in dictionary)

**Matching**:
1. Exact match check: `MANGA_ALIASES["ãƒ¯ãƒ³ãƒ”ãƒ¼ã‚¹"]`? **YES** â†’ Returns immediately âœ…

**OK, exact match works.**

But what about:
**User types**: `"ã‚ã‚“ã´"` (Hiragana abbreviation)
**After normalization**: `"ãƒ¯ãƒ³ãƒ”"` (Katakana)
**Exact match**: `MANGA_ALIASES["ãƒ¯ãƒ³ãƒ”"]`? **YES** â†’ Returns immediately âœ…

**Also OK.**

---

## ğŸš¨ CRITICAL FLAW #4: Unnecessary Complexity

### Current Problem
- "ãƒ¯ãƒ³ãƒ”ãƒ¼ã‚¹ ãƒãƒ§ãƒƒãƒ‘ãƒ¼" â†’ "ONE PIECEãƒ¼ã‚¹ ãƒãƒ§ãƒƒãƒ‘ãƒ¼"

### Root Cause
- Partial match finds both "ãƒ¯ãƒ³ãƒ”" and "ãƒ¯ãƒ³ãƒ”ãƒ¼ã‚¹"
- Shortest-first sort picks "ãƒ¯ãƒ³ãƒ”"
- Naive replacement creates garbage

### Simplest Fix (Overlooked)

**Why are we even doing partial matching for compound queries?**

**Alternative Approach**: 
Only use the **FIRST TOKEN** for alias resolution:

```typescript
// Before alias resolution
const tokens = normalizedChars.split(/[\sã€€]+/);
const firstToken = tokens[0];

// Resolve only the first token
const aliasResult = resolveAlias(cleanedQuery, firstToken);

if (aliasResult) {
    // Replace only the first token
    const remainingTokens = tokens.slice(1).join(' ');
    finalNormalized = aliasResult.resolved + (remainingTokens ? ' ' + remainingTokens : '');
}
```

**Test**:
- Input: "ãƒ¯ãƒ³ãƒ”ãƒ¼ã‚¹ ãƒãƒ§ãƒƒãƒ‘ãƒ¼"
- First token: "ãƒ¯ãƒ³ãƒ”ãƒ¼ã‚¹"
- Exact match: "ãƒ¯ãƒ³ãƒ”ãƒ¼ã‚¹" â†’ "ONE PIECE"
- Final: "ONE PIECE ãƒãƒ§ãƒƒãƒ‘ãƒ¼" âœ…

**Benefits**:
1. âœ… No complex sorting logic
2. âœ… No regex needed
3. âœ… Preserves all other tokens
4. âœ… Fails gracefully for compound words like "ãƒ¯ãƒ³ãƒ”ãƒ¼ã‚¹ãƒ‘ãƒ¼ãƒ†ã‚£ãƒ¼" (treated as single token)

**Drawbacks**:
- What if the manga title itself contains spaces? E.g., "Hunter Ã— Hunter"
- After normalization, might become "HunterÃ—Hunter" (no space)
- So this is probably fine

---

## ğŸ¯ RECOMMENDATION

**REJECT Round 4 Proposal.**

**Adopt "First Token Only" approach instead**:
1. Split `normalizedChars` by whitespace
2. Resolve only the first token
3. Reconstruct with resolved first token + remaining tokens

**Code Changes**: `normalizer.ts` Lines 190-214

**Risk**: LOW (simpler logic, fewer edge cases)
**Benefit**: Solves the bug without introducing complexity

---

## Final Verdict

**The Round 4 proposal is over-engineered.**

"First Token Only" is:
- âœ… Simpler
- âœ… Safer
- âœ… Faster (no regex)
- âœ… More predictable

**Approve "First Token Only" approach instead.**
